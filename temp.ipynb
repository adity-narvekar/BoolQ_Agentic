{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba037677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble1_train.csv\")\n",
    "train_incorrect = df_train[df_train[\"actual_answer\"] != df_train[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d278899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble1_valid.csv\")\n",
    "valid_incorrect = df_valid[df_valid[\"actual_answer\"] != df_valid[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ea7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\"train_incorrect\": train_incorrect, \"valid_incorrect\": valid_incorrect}\n",
    "\n",
    "with open(\"ensemble1_incorrect.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daada2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akula\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "with open(\"ensemble1_incorrect.json\", \"r\") as f:\n",
    "    incorrect_data = json.load(f)\n",
    "\n",
    "train_indices = set(i - 1 for i in incorrect_data[\"train_incorrect\"])\n",
    "valid_indices = set(i - 1 for i in incorrect_data[\"valid_incorrect\"])\n",
    "\n",
    "dataset = load_dataset(\"boolq\", split=\"train\")\n",
    "train_rows = [dataset[i] for i in train_indices]\n",
    "dataset = load_dataset(\"boolq\", split=\"validation\")\n",
    "valid_rows = [dataset[i] for i in valid_indices]\n",
    "\n",
    "all_rows = train_rows + valid_rows\n",
    "\n",
    "df_train = pd.DataFrame(all_rows)\n",
    "\n",
    "df_train.to_csv(\"ensemble1_wrong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f9c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble2_train.csv\")\n",
    "train_incorrect = df_train[df_train[\"actual_answer\"] != df_train[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d90f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble2_valid.csv\")\n",
    "valid_incorrect = df_valid[df_valid[\"actual_answer\"] != df_valid[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bff23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\"train_incorrect\": train_incorrect, \"valid_incorrect\": valid_incorrect}\n",
    "\n",
    "with open(\"ensemble2_incorrect.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a4b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akula\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "with open(\"ensemble2_incorrect.json\", \"r\") as f:\n",
    "    incorrect_data = json.load(f)\n",
    "\n",
    "train_indices = set(i - 1 for i in incorrect_data[\"train_incorrect\"])\n",
    "valid_indices = set(i - 1 for i in incorrect_data[\"valid_incorrect\"])\n",
    "\n",
    "dataset = load_dataset(\"boolq\", split=\"train\")\n",
    "train_rows = [dataset[i] for i in train_indices]\n",
    "dataset = load_dataset(\"boolq\", split=\"validation\")\n",
    "valid_rows = [dataset[i] for i in valid_indices]\n",
    "\n",
    "all_rows = train_rows + valid_rows\n",
    "\n",
    "df_train = pd.DataFrame(all_rows)\n",
    "\n",
    "df_train.to_csv(\"ensemble2_wrong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cda71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble3_train.csv\")\n",
    "train_incorrect = df_train[df_train[\"actual_answer\"] != df_train[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84754247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble3_valid.csv\")\n",
    "valid_incorrect = df_valid[df_valid[\"actual_answer\"] != df_valid[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\"train_incorrect\": train_incorrect, \"valid_incorrect\": valid_incorrect}\n",
    "\n",
    "with open(\"ensemble3_incorrect.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f536f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "with open(\"ensemble3_incorrect.json\", \"r\") as f:\n",
    "    incorrect_data = json.load(f)\n",
    "\n",
    "train_indices = set(i - 1 for i in incorrect_data[\"train_incorrect\"])\n",
    "valid_indices = set(i - 1 for i in incorrect_data[\"valid_incorrect\"])\n",
    "\n",
    "dataset = load_dataset(\"boolq\", split=\"train\")\n",
    "train_rows = [dataset[i] for i in train_indices]\n",
    "dataset = load_dataset(\"boolq\", split=\"validation\")\n",
    "valid_rows = [dataset[i] for i in valid_indices]\n",
    "\n",
    "all_rows = train_rows + valid_rows\n",
    "\n",
    "df_train = pd.DataFrame(all_rows)\n",
    "\n",
    "df_train.to_csv(\"ensemble3_wrong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac10ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble4_train.csv\")\n",
    "train_incorrect = df_train[df_train[\"actual_answer\"] != df_train[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc71a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble4_valid.csv\")\n",
    "valid_incorrect = df_valid[df_valid[\"actual_answer\"] != df_valid[\"ensemble_pred\"]][\"q_number\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc212bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\"train_incorrect\": train_incorrect, \"valid_incorrect\": valid_incorrect}\n",
    "\n",
    "with open(\"ensemble4_incorrect.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92d4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "with open(\"ensemble4_incorrect.json\", \"r\") as f:\n",
    "    incorrect_data = json.load(f)\n",
    "\n",
    "train_indices = set(i - 1 for i in incorrect_data[\"train_incorrect\"])\n",
    "valid_indices = set(i - 1 for i in incorrect_data[\"valid_incorrect\"])\n",
    "\n",
    "dataset = load_dataset(\"boolq\", split=\"train\")\n",
    "train_rows = [dataset[i] for i in train_indices]\n",
    "dataset = load_dataset(\"boolq\", split=\"validation\")\n",
    "valid_rows = [dataset[i] for i in valid_indices]\n",
    "\n",
    "all_rows = train_rows + valid_rows\n",
    "\n",
    "df_train = pd.DataFrame(all_rows)\n",
    "\n",
    "df_train.to_csv(\"ensemble4_wrong.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b1eeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble1_model.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_model_wrong_counts(df):\n",
    "    llm_pred_cols = [col for col in df.columns if col.endswith(\"_pred\") and col != \"ensemble_pred\"]\n",
    "    wrong = df[df[\"actual_answer\"] != df[\"ensemble_pred\"]]\n",
    "    counts = {}\n",
    "    for col in llm_pred_cols:\n",
    "        counts[col] = int((wrong[col] != wrong[\"actual_answer\"]).sum())\n",
    "    counts[\"total_ensemble_wrong\"] = len(wrong)\n",
    "    return counts\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble1_train.csv\")\n",
    "train_counts = get_model_wrong_counts(df_train)\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble1_valid.csv\")\n",
    "valid_counts = get_model_wrong_counts(df_valid)\n",
    "\n",
    "output = {\n",
    "    \"train\": train_counts,\n",
    "    \"valid\": valid_counts\n",
    "}\n",
    "\n",
    "with open(\"ensemble1_model.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"Saved ensemble1_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "818c7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble2_model.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_model_wrong_counts(df):\n",
    "    llm_pred_cols = [col for col in df.columns if col.endswith(\"_pred\") and col != \"ensemble_pred\"]\n",
    "    wrong = df[df[\"actual_answer\"] != df[\"ensemble_pred\"]]\n",
    "    counts = {}\n",
    "    for col in llm_pred_cols:\n",
    "        counts[col] = int((wrong[col] != wrong[\"actual_answer\"]).sum())\n",
    "    counts[\"total_ensemble_wrong\"] = len(wrong)\n",
    "    return counts\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble2_train.csv\")\n",
    "train_counts = get_model_wrong_counts(df_train)\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble2_valid.csv\")\n",
    "valid_counts = get_model_wrong_counts(df_valid)\n",
    "\n",
    "output = {\n",
    "    \"train\": train_counts,\n",
    "    \"valid\": valid_counts\n",
    "}\n",
    "\n",
    "with open(\"ensemble2_model.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"Saved ensemble2_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21f134a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble3_model.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_model_wrong_counts(df):\n",
    "    llm_pred_cols = [col for col in df.columns if col.endswith(\"_pred\") and col != \"ensemble_pred\"]\n",
    "    wrong = df[df[\"actual_answer\"] != df[\"ensemble_pred\"]]\n",
    "    counts = {}\n",
    "    for col in llm_pred_cols:\n",
    "        counts[col] = int((wrong[col] != wrong[\"actual_answer\"]).sum())\n",
    "    counts[\"total_ensemble_wrong\"] = len(wrong)\n",
    "    return counts\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble3_train.csv\")\n",
    "train_counts = get_model_wrong_counts(df_train)\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble3_valid.csv\")\n",
    "valid_counts = get_model_wrong_counts(df_valid)\n",
    "\n",
    "output = {\n",
    "    \"train\": train_counts,\n",
    "    \"valid\": valid_counts\n",
    "}\n",
    "\n",
    "with open(\"ensemble3_model.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"Saved ensemble3_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d720a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble4_model.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_model_wrong_counts(df):\n",
    "    llm_pred_cols = [col for col in df.columns if col.endswith(\"_pred\") and col != \"ensemble_pred\"]\n",
    "    wrong = df[df[\"actual_answer\"] != df[\"ensemble_pred\"]]\n",
    "    counts = {}\n",
    "    for col in llm_pred_cols:\n",
    "        counts[col] = int((wrong[col] != wrong[\"actual_answer\"]).sum())\n",
    "    counts[\"total_ensemble_wrong\"] = len(wrong)\n",
    "    return counts\n",
    "\n",
    "df_train = pd.read_csv(\"ensemble4_train.csv\")\n",
    "train_counts = get_model_wrong_counts(df_train)\n",
    "\n",
    "df_valid = pd.read_csv(\"ensemble4_valid.csv\")\n",
    "valid_counts = get_model_wrong_counts(df_valid)\n",
    "\n",
    "output = {\n",
    "    \"train\": train_counts,\n",
    "    \"valid\": valid_counts\n",
    "}\n",
    "\n",
    "with open(\"ensemble4_model.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"Saved ensemble4_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe30a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3258\n",
      "4o correct: 2950, accuracy: 0.906855210574854\n",
      "r1 correct: 2865, accuracy: 0.896433041301627\n",
      "Total: 3262\n",
      "41_mini correct: 2907, accuracy: 0.8917177914110429\n",
      "41 correct: 2908, accuracy: 0.8920245398773006\n",
      "Total: 3261\n",
      "4omini correct: 2913, accuracy: 0.8941068139963168\n",
      "phi correct: 2816, accuracy: 0.8742626513505123\n",
      "mistral correct: 2525, accuracy: 0.8316864295125165\n",
      "llama correct: 2739, accuracy: 0.8412162162162162\n",
      "Total: 9394\n",
      "4o correct: 8457, accuracy: 0.9039119281744336\n",
      "41 correct: 8326, accuracy: 0.8870658427445131\n",
      "r1 correct: 8017, accuracy: 0.8914711442232848\n",
      "4omini correct: 8351, accuracy: 0.889729384189218\n",
      "41_mini correct: 8343, accuracy: 0.8884037908635928\n",
      "phi correct: 8292, accuracy: 0.8959481361426256\n",
      "mistral correct: 7093, accuracy: 0.831535756154748\n",
      "llama correct: 7827, accuracy: 0.8362179487179487\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"model12_valid.csv\")\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\")\n",
    "    return bool(x)\n",
    "\n",
    "for col in [\"actual_answer\", \"4o_pred\", \"r1_pred\"]:\n",
    "    df[col] = df[col].apply(to_bool)\n",
    "\n",
    "n = len(df)\n",
    "denom_4o = int(df[\"4o_pred\"].notna().sum())\n",
    "denom_r1 = int(df[\"r1_pred\"].notna().sum())\n",
    "correct_4o = int(((df[\"4o_pred\"] == df[\"actual_answer\"]) & df[\"4o_pred\"].notna()).sum())\n",
    "correct_r1 = int(((df[\"r1_pred\"] == df[\"actual_answer\"]) & df[\"r1_pred\"].notna()).sum())\n",
    "\n",
    "acc_4o = correct_4o / denom_4o if denom_4o else 0.0\n",
    "acc_r1 = correct_r1 / denom_r1 if denom_r1 else 0.0\n",
    "\n",
    "print(f\"Total: {n}\")\n",
    "print(f\"4o correct: {correct_4o}, accuracy: {acc_4o:}\")\n",
    "print(f\"r1 correct: {correct_r1}, accuracy: {acc_r1:}\")\n",
    "\n",
    "df = pd.read_csv(\"model78_valid.csv\")\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\")\n",
    "    return bool(x)\n",
    "\n",
    "for col in [\"actual_answer\", \"41_mini_pred\", \"41_pred\"]:\n",
    "    df[col] = df[col].apply(to_bool)\n",
    "\n",
    "n = len(df)\n",
    "denom_41_mini = int(df[\"41_mini_pred\"].notna().sum())\n",
    "denom_41 = int(df[\"41_pred\"].notna().sum())\n",
    "correct_41_mini = int(((df[\"41_mini_pred\"] == df[\"actual_answer\"]) & df[\"41_mini_pred\"].notna()).sum())\n",
    "correct_41 = int(((df[\"41_pred\"] == df[\"actual_answer\"]) & df[\"41_pred\"].notna()).sum())\n",
    "\n",
    "acc_41_mini = correct_41_mini / denom_41_mini if denom_41_mini else 0.0\n",
    "acc_41 = correct_41 / denom_41 if denom_41 else 0.0\n",
    "\n",
    "print(f\"Total: {n}\")\n",
    "print(f\"41_mini correct: {correct_41_mini}, accuracy: {acc_41_mini:}\")\n",
    "print(f\"41 correct: {correct_41}, accuracy: {acc_41:}\")\n",
    "\n",
    "df = pd.read_csv(\"model3456_valid.csv\")\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\")\n",
    "    return bool(x)\n",
    "\n",
    "for col in [\"actual_answer\", \"4omini_pred\", \"phi_pred\", \"mistral_pred\", \"llama_pred\"]:\n",
    "    df[col] = df[col].apply(to_bool)\n",
    "\n",
    "n = len(df)\n",
    "denom_4omini = int(df[\"4omini_pred\"].notna().sum())\n",
    "denom_phi = int(df[\"phi_pred\"].notna().sum())\n",
    "denom_mistral = int(df[\"mistral_pred\"].notna().sum())\n",
    "denom_llama = int(df[\"llama_pred\"].notna().sum())\n",
    "\n",
    "correct_4omini = int(((df[\"4omini_pred\"] == df[\"actual_answer\"]) & df[\"4omini_pred\"].notna()).sum())\n",
    "correct_phi = int(((df[\"phi_pred\"] == df[\"actual_answer\"]) & df[\"phi_pred\"].notna()).sum())\n",
    "correct_mistral = int(((df[\"mistral_pred\"] == df[\"actual_answer\"]) & df[\"mistral_pred\"].notna()).sum())\n",
    "correct_llama = int(((df[\"llama_pred\"] == df[\"actual_answer\"]) & df[\"llama_pred\"].notna()).sum())\n",
    "\n",
    "acc_4omini = correct_4omini / denom_4omini if denom_4omini else 0.0\n",
    "acc_phi = correct_phi / denom_phi if denom_phi else 0.0\n",
    "acc_mistral = correct_mistral / denom_mistral if denom_mistral else 0.0\n",
    "acc_llama = correct_llama / denom_llama if denom_llama else 0.0\n",
    "\n",
    "print(f\"Total: {n}\")\n",
    "print(f\"4omini correct: {correct_4omini}, accuracy: {acc_4omini:}\")\n",
    "print(f\"phi correct: {correct_phi}, accuracy: {acc_phi:}\")\n",
    "print(f\"mistral correct: {correct_mistral}, accuracy: {acc_mistral:}\")\n",
    "print(f\"llama correct: {correct_llama}, accuracy: {acc_llama:}\")\n",
    "\n",
    "df = pd.read_csv(\"all_train.csv\")\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\")\n",
    "    return bool(x)\n",
    "\n",
    "cols = [\"actual_answer\",\"4o_pred\",\"41_pred\",\"r1_pred\",\"4omini_pred\",\"41_mini_pred\",\"phi_pred\",\"mistral_pred\",\"llama_pred\"]\n",
    "for col in cols:\n",
    "    df[col] = df[col].apply(to_bool)\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "def correct_and_denom(pred_col):\n",
    "    denom = int(df[pred_col].notna().sum())\n",
    "    correct = int(((df[pred_col] == df[\"actual_answer\"]) & df[pred_col].notna()).sum())\n",
    "    return correct, denom\n",
    "\n",
    "correct_4o, denom_4o = correct_and_denom(\"4o_pred\")\n",
    "correct_41, denom_41 = correct_and_denom(\"41_pred\")\n",
    "correct_r1, denom_r1 = correct_and_denom(\"r1_pred\")\n",
    "correct_4omini, denom_4omini = correct_and_denom(\"4omini_pred\")\n",
    "correct_41_mini, denom_41_mini = correct_and_denom(\"41_mini_pred\")\n",
    "correct_phi, denom_phi = correct_and_denom(\"phi_pred\")\n",
    "correct_mistral, denom_mistral = correct_and_denom(\"mistral_pred\")\n",
    "correct_llama, denom_llama = correct_and_denom(\"llama_pred\")\n",
    "\n",
    "acc_4o = correct_4o / denom_4o if denom_4o else 0.0\n",
    "acc_41 = correct_41 / denom_41 if denom_41 else 0.0\n",
    "acc_r1 = correct_r1 / denom_r1 if denom_r1 else 0.0\n",
    "acc_4omini = correct_4omini / denom_4omini if denom_4omini else 0.0\n",
    "acc_41_mini = correct_41_mini / denom_41_mini if denom_41_mini else 0.0\n",
    "acc_phi = correct_phi / denom_phi if denom_phi else 0.0\n",
    "acc_mistral = correct_mistral / denom_mistral if denom_mistral else 0.0\n",
    "acc_llama = correct_llama / denom_llama if denom_llama else 0.0\n",
    "\n",
    "print(f\"Total: {n}\")\n",
    "print(f\"4o correct: {correct_4o}, accuracy: {acc_4o:}\")\n",
    "print(f\"41 correct: {correct_41}, accuracy: {acc_41:}\")\n",
    "print(f\"r1 correct: {correct_r1}, accuracy: {acc_r1:}\")\n",
    "print(f\"4omini correct: {correct_4omini}, accuracy: {acc_4omini:}\")\n",
    "print(f\"41_mini correct: {correct_41_mini}, accuracy: {acc_41_mini:}\")\n",
    "print(f\"phi correct: {correct_phi}, accuracy: {acc_phi:}\")\n",
    "print(f\"mistral correct: {correct_mistral}, accuracy: {acc_mistral:}\")\n",
    "print(f\"llama correct: {correct_llama}, accuracy: {acc_llama:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9283053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble1_train.csv: accuracy: 0.8674775928297055 (8130/9372)\n",
      "ensemble1_valid.csv: accuracy: 0.859159251304081 (2800/3259)\n",
      "ensemble2_train.csv: accuracy: 0.8898495036823567 (8337/9369)\n",
      "ensemble2_valid.csv: accuracy: 0.8857844642308873 (2885/3257)\n",
      "ensemble3_train.csv: accuracy: 0.8925417597616768 (8389/9399)\n",
      "ensemble3_valid.csv: accuracy: 0.8896382587369712 (2902/3262)\n",
      "ensemble3_1_train.csv: accuracy: 0.6585067319461444 (538/817)\n",
      "ensemble3_1_valid.csv: accuracy: 0.6931034482758621 (201/290)\n",
      "ensemble4_train.csv: accuracy: 0.9026388593317727 (8483/9398)\n",
      "ensemble4_valid.csv: accuracy: 0.8984662576687117 (2929/3260)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower() in (\"true\", \"1\", \"yes\")\n",
    "    return bool(x)\n",
    "\n",
    "def compute_accuracy(csv_path, model_cols, ensemble_col=\"ensemble_pred\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    non_na = df[model_cols].notna().sum(axis=1)\n",
    "    threshold = len(model_cols) // 2 + 1\n",
    "    mask = (non_na >= threshold) & df[ensemble_col].notna() & df[\"actual_answer\"].notna()\n",
    "    df_f = df[mask].copy()\n",
    "    df_f[ensemble_col] = df_f[ensemble_col].apply(to_bool)\n",
    "    df_f[\"actual_answer\"] = df_f[\"actual_answer\"].apply(to_bool)\n",
    "    denom = len(df_f)\n",
    "    correct = int((df_f[ensemble_col] == df_f[\"actual_answer\"]).sum())\n",
    "    acc = correct / denom if denom else 0.0\n",
    "    return {\"file\": csv_path, \"accuracy\": acc, \"correct\": correct, \"denom\": denom}\n",
    "\n",
    "files = [\n",
    "    (\"ensemble1_train.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\"]),\n",
    "    (\"ensemble1_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\"]),\n",
    "    (\"ensemble2_train.csv\", [\"phi_pred\",\"mistral_pred\",\"gpt4o_mini_pred\"]),\n",
    "    (\"ensemble2_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"gpt4o_mini_pred\"]),\n",
    "    (\"ensemble3_train.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    (\"ensemble3_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    (\"ensemble3_1_train.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    (\"ensemble3_1_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    (\"ensemble4_train.csv\", [\"phi_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    (\"ensemble4_valid.csv\", [\"phi_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"])\n",
    "]\n",
    "\n",
    "results = [compute_accuracy(f, cols) for f, cols in files]\n",
    "for r in results:\n",
    "    print(f\"{r['file']}: accuracy: {r['accuracy']} ({r['correct']}/{r['denom']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95240fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: modellarge_train.csv  (total rows: 9405)\n",
      "  jamba_pred: accuracy: 0.9102947458351132 (8524/9364)\n",
      "  llama70_pred: accuracy: 0.9103572947681837 (8561/9404)\n",
      "  llama405_pred: accuracy: 0.902452025586354 (8465/9380)\n",
      "\n",
      "File: modellarge_valid.csv  (total rows: 3262)\n",
      "  jamba_pred: accuracy: 0.9132040627885504 (2967/3249)\n",
      "  llama70_pred: accuracy: 0.9080318822808093 (2962/3262)\n",
      "  llama405_pred: accuracy: 0.902117213869285 (2940/3259)\n",
      "\n",
      "File: gpt4o(1)_train_results.csv  (total rows: 9404)\n",
      "  4o_pred: accuracy: 0.9034497490120688 (8459/9363)\n",
      "\n",
      "File: gpt4o(2)_train_results.csv  (total rows: 9404)\n",
      "  4o_pred: accuracy: 0.9035565523870555 (8460/9363)\n",
      "\n",
      "File: gpt4o(1)_valid_results.csv  (total rows: 3262)\n",
      "  4o_pred: accuracy: 0.9071911493546404 (2952/3254)\n",
      "\n",
      "File: gpt4o(2)_valid_results.csv  (total rows: 3262)\n",
      "  4o_pred: accuracy: 0.9053472649047326 (2946/3254)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_bool(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip().lower()\n",
    "        if s in (\"true\",\"1\",\"yes\"):\n",
    "            return True\n",
    "        if s in (\"false\",\"0\",\"no\"):\n",
    "            return False\n",
    "    return bool(x)\n",
    "\n",
    "def report_by_non_na(csv_path, pred_cols):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for col in [\"actual_answer\"] + pred_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(to_bool)\n",
    "    n = len(df)\n",
    "    print(f\"\\nFile: {csv_path}  (total rows: {n})\")\n",
    "    for p in pred_cols:\n",
    "        if p not in df.columns:\n",
    "            print(f\"  {p}: not in file\")\n",
    "            continue\n",
    "        denom = int(df[p].notna().sum())\n",
    "        correct = int(((df[p] == df[\"actual_answer\"]) & df[p].notna()).sum())\n",
    "        acc = correct / denom if denom else 0.0\n",
    "        print(f\"  {p}: accuracy: {acc} ({correct}/{denom})\")\n",
    "\n",
    "files_modellarge = [\n",
    "    (\"modellarge_train.csv\", [\"jamba_pred\",\"llama70_pred\",\"llama405_pred\"]),\n",
    "    (\"modellarge_valid.csv\", [\"jamba_pred\",\"llama70_pred\",\"llama405_pred\"]),\n",
    "]\n",
    "\n",
    "files_gpt4o = [\n",
    "    (\"gpt4o(1)_train_results.csv\", [\"4o_pred\"]),\n",
    "    (\"gpt4o(2)_train_results.csv\", [\"4o_pred\"]),\n",
    "    (\"gpt4o(1)_valid_results.csv\", [\"4o_pred\"]),\n",
    "    (\"gpt4o(2)_valid_results.csv\", [\"4o_pred\"]),\n",
    "]\n",
    "\n",
    "for f, cols in files_modellarge + files_gpt4o:\n",
    "    report_by_non_na(f, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26176767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "4o(1): 0.9039119281744336\n",
      "4o(2): 0.9034497490120688\n",
      "4o(3): 0.9035565523870555\n",
      "41_pred: 0.8870658427445131\n",
      "r1_pred: 0.8914711442232848\n",
      "4omini_pred: 0.889729384189218\n",
      "41_mini_pred: 0.8884037908635928\n",
      "phi_pred: 0.8959481361426256\n",
      "mistral_pred: 0.831535756154748\n",
      "llama_pred: 0.8362179487179487\n",
      "jamba_pred: 0.9102947458351132\n",
      "llama70_pred: 0.9103572947681837\n",
      "llama405_pred: 0.902452025586354\n",
      "ensemble1: 0.8674775928297055\n",
      "ensemble2: 0.8898495036823567\n",
      "ensemble3: 0.8925417597616768\n",
      "ensemble4: 0.9026388593317727\n",
      "\n",
      "Valid:\n",
      "4o(1): 0.906855210574854\n",
      "4o(2): 0.9071911493546404\n",
      "4o(3): 0.9053472649047326\n",
      "41_pred: 0.8920245398773006\n",
      "r1_pred: 0.896433041301627\n",
      "4omini_pred: 0.8941068139963168\n",
      "41_mini_pred: 0.8917177914110429\n",
      "phi_pred: 0.8742626513505123\n",
      "mistral_pred: 0.8316864295125165\n",
      "llama_pred: 0.8412162162162162\n",
      "jamba_pred: 0.9132040627885504\n",
      "llama70_pred: 0.9080318822808093\n",
      "llama405_pred: 0.902117213869285\n",
      "ensemble1: 0.859159251304081\n",
      "ensemble2: 0.8857844642308873\n",
      "ensemble3: 0.8896382587369712\n",
      "ensemble4: 0.8984662576687117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def to_bool(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip().lower()\n",
    "        if s in (\"true\",\"1\",\"yes\"):\n",
    "            return True\n",
    "        if s in (\"false\",\"0\",\"no\"):\n",
    "            return False\n",
    "    return bool(x)\n",
    "\n",
    "def compute_individual_accuracy(pred_name, csv_paths):\n",
    "    total_denom = 0\n",
    "    total_correct = 0\n",
    "    for p in csv_paths:\n",
    "        if not Path(p).exists():\n",
    "            continue\n",
    "        df = pd.read_csv(p)\n",
    "        if pred_name not in df.columns or \"actual_answer\" not in df.columns:\n",
    "            continue\n",
    "        df[\"actual_answer\"] = df[\"actual_answer\"].apply(to_bool)\n",
    "        df[pred_name] = df[pred_name].apply(to_bool)\n",
    "        denom = int(df[pred_name].notna().sum())\n",
    "        correct = int(((df[pred_name] == df[\"actual_answer\"]) & df[pred_name].notna()).sum())\n",
    "        total_denom += denom\n",
    "        total_correct += correct\n",
    "    return (total_correct / total_denom) if total_denom else 0.0\n",
    "\n",
    "def compute_ensemble_accuracy(csv_path, model_cols, ensemble_col=\"ensemble_pred\"):\n",
    "    if not Path(csv_path).exists():\n",
    "        return 0.0\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"actual_answer\" not in df.columns or ensemble_col not in df.columns:\n",
    "        return 0.0\n",
    "    df[\"actual_answer\"] = df[\"actual_answer\"].apply(to_bool)\n",
    "    df[ensemble_col] = df[ensemble_col].apply(to_bool)\n",
    "    present_cols = [c for c in model_cols if c in df.columns]\n",
    "    if not present_cols:\n",
    "        return 0.0\n",
    "    non_na = df[present_cols].notna().sum(axis=1)\n",
    "    threshold = len(present_cols) // 2 + 1\n",
    "    mask = (non_na >= threshold) & df[ensemble_col].notna() & df[\"actual_answer\"].notna()\n",
    "    df_f = df[mask].copy()\n",
    "    denom = len(df_f)\n",
    "    correct = int((df_f[ensemble_col] == df_f[\"actual_answer\"]).sum())\n",
    "    return (correct / denom) if denom else 0.0\n",
    "\n",
    "train_files = [\"all_train.csv\", \"modellarge_train.csv\", \"gpt4o(1)_train_results.csv\", \"gpt4o(2)_train_results.csv\"]\n",
    "valid_files = [\"model12_valid.csv\", \"model78_valid.csv\", \"model3456_valid.csv\", \"modellarge_valid.csv\", \"gpt4o(1)_valid_results.csv\", \"gpt4o(2)_valid_results.csv\"]\n",
    "\n",
    "train_individuals = [\n",
    "    (\"4o(1)\", \"4o_pred\", [\"all_train.csv\"]),\n",
    "    (\"4o(2)\", \"4o_pred\", [\"gpt4o(1)_train_results.csv\"]),\n",
    "    (\"4o(3)\", \"4o_pred\", [\"gpt4o(2)_train_results.csv\"]),\n",
    "    (\"41_pred\", \"41_pred\", train_files),\n",
    "    (\"r1_pred\", \"r1_pred\", train_files),\n",
    "    (\"4omini_pred\", \"4omini_pred\", train_files),\n",
    "    (\"41_mini_pred\", \"41_mini_pred\", train_files),\n",
    "    (\"phi_pred\", \"phi_pred\", train_files),\n",
    "    (\"mistral_pred\", \"mistral_pred\", train_files),\n",
    "    (\"llama_pred\", \"llama_pred\", train_files),\n",
    "    (\"jamba_pred\", \"jamba_pred\", [\"modellarge_train.csv\"]),\n",
    "    (\"llama70_pred\", \"llama70_pred\", [\"modellarge_train.csv\"]),\n",
    "    (\"llama405_pred\", \"llama405_pred\", [\"modellarge_train.csv\"]),\n",
    "]\n",
    "\n",
    "valid_individuals = [\n",
    "    (\"4o(1)\", \"4o_pred\", [\"model12_valid.csv\"]),\n",
    "    (\"4o(2)\", \"4o_pred\", [\"gpt4o(1)_valid_results.csv\"]),\n",
    "    (\"4o(3)\", \"4o_pred\", [\"gpt4o(2)_valid_results.csv\"]),\n",
    "    (\"41_pred\", \"41_pred\", valid_files),\n",
    "    (\"r1_pred\", \"r1_pred\", valid_files),\n",
    "    (\"4omini_pred\", \"4omini_pred\", valid_files),\n",
    "    (\"41_mini_pred\", \"41_mini_pred\", valid_files),\n",
    "    (\"phi_pred\", \"phi_pred\", valid_files),\n",
    "    (\"mistral_pred\", \"mistral_pred\", valid_files),\n",
    "    (\"llama_pred\", \"llama_pred\", valid_files),\n",
    "    (\"jamba_pred\", \"jamba_pred\", [\"modellarge_valid.csv\"]),\n",
    "    (\"llama70_pred\", \"llama70_pred\", [\"modellarge_valid.csv\"]),\n",
    "    (\"llama405_pred\", \"llama405_pred\", [\"modellarge_valid.csv\"]),\n",
    "]\n",
    "\n",
    "ensemble_train_files = {\n",
    "    \"ensemble1\": (\"ensemble1_train.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\"]),\n",
    "    \"ensemble2\": (\"ensemble2_train.csv\", [\"phi_pred\",\"mistral_pred\",\"gpt4o_mini_pred\"]),\n",
    "    \"ensemble3\": (\"ensemble3_train.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    \"ensemble4\": (\"ensemble4_train.csv\", [\"phi_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "}\n",
    "ensemble_valid_files = {\n",
    "    \"ensemble1\": (\"ensemble1_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\"]),\n",
    "    \"ensemble2\": (\"ensemble2_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"gpt4o_mini_pred\"]),\n",
    "    \"ensemble3\": (\"ensemble3_valid.csv\", [\"phi_pred\",\"mistral_pred\",\"llama_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "    \"ensemble4\": (\"ensemble4_valid.csv\", [\"phi_pred\",\"gpt4o_mini_pred\",\"gpt41_mini_pred\"]),\n",
    "}\n",
    "\n",
    "print(\"Train:\")\n",
    "for label, col, paths in train_individuals:\n",
    "    acc = compute_individual_accuracy(col, paths)\n",
    "    print(f\"{label}: {acc}\")\n",
    "for name, (path, cols) in ensemble_train_files.items():\n",
    "    acc = compute_ensemble_accuracy(path, cols, ensemble_col=\"ensemble_pred\")\n",
    "    print(f\"{name}: {acc}\")\n",
    "\n",
    "print(\"\\nValid:\")\n",
    "for label, col, paths in valid_individuals:\n",
    "    acc = compute_individual_accuracy(col, paths)\n",
    "    print(f\"{label}: {acc}\")\n",
    "for name, (path, cols) in ensemble_valid_files.items():\n",
    "    acc = compute_ensemble_accuracy(path, cols, ensemble_col=\"ensemble_pred\")\n",
    "    print(f\"{name}: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
