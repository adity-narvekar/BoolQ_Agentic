{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30816702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating OpenAI GPT-4o...\n",
      "Skipping sample 451 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 927 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'high'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 937 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 989 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 1879 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'high'}, 'violence': {'filtered': False, 'severity': 'low'}}}}}\n",
      "Skipping sample 2352 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 2978 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 3163 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': True, 'detected': True}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}}}\n",
      "Skipping sample 3551 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 4017 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 4301 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 5203 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 5616 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 5708 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 6028 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'low'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 6306 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 6442 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 6701 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 6713 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 7464 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 8104 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Skipping sample 8148 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Skipping sample 8297 due to error: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'low'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluated\n",
      "Evaluating OpenAI GPT-4.1...\n",
      "Evaluated\n",
      "Evaluating DeepSeek R1...\n",
      "Skipping sample 1414 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Skipping sample 1465 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Skipping sample 4594 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Skipping sample 6370 due to error: 'NoneType' object has no attribute 'strip'\n",
      "Skipping sample 7377 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Skipping sample 7588 due to error: 'NoneType' object has no attribute 'strip'\n",
      "Skipping sample 7620 due to error: 'NoneType' object has no attribute 'strip'\n",
      "Skipping sample 7848 due to error: 'NoneType' object has no attribute 'strip'\n",
      "Skipping sample 8032 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Skipping sample 8660 due to error: HTTPSConnectionPool(host='deepseek-r1-trbxn.eastus2.models.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Evaluated\n",
      "Evaluating OpenAI GPT-4o-mini...\n",
      "Evaluated\n",
      "Evaluating OpenAI GPT-4.1-mini...\n",
      "Evaluated\n",
      "Evaluating Phi...\n",
      "Evaluated\n",
      "Evaluating Mistral NeMo...\n",
      "Evaluated\n",
      "Evaluating LLaMA 8B...\n",
      "Evaluated\n",
      "Saved results to results.csv\n",
      "Final Accuracies:\n",
      "OpenAI GPT-4o: 0.90\n",
      "GPT-41: 0.89\n",
      "DeepSeek R1: 0.85\n",
      "GPT-4o-mini: 0.89\n",
      "GPT-41-mini: 0.89\n",
      "Phi: 0.88\n",
      "Mistral NeMo: 0.76\n",
      "LLaMA 8B: 0.83\n",
      "Saved accuracies to final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "import string\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import UserMessage\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv(\"env.env\")\n",
    "\n",
    "llm4o = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "llm41 = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"GPT_4_1_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"GPT_4_1_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "client_deepseek = ChatCompletionsClient(\n",
    "    endpoint=os.getenv(\"DEEPSEEKR1_ENDPOINT\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"DEEPSEEKR1_KEY\"))\n",
    ")\n",
    "\n",
    "client_phi = ChatCompletionsClient(\n",
    "    endpoint=os.getenv(\"PHI_AZURE_ENDPOINT\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"PHI_AZURE_KEY\"))\n",
    ")\n",
    "\n",
    "client_mistral = ChatCompletionsClient(\n",
    "    endpoint=os.getenv(\"MISTRAL_ENDPOINT\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"MISTRAL_KEY\"))\n",
    ")\n",
    "\n",
    "client_llama = ChatCompletionsClient(\n",
    "    endpoint=os.getenv(\"LLAMA_3_8B_ENDPOINT\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"LLAMA_3_8B_KEY\"))\n",
    ")\n",
    "\n",
    "def get_4o_completion(prompt, temperature=0.1):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = llm4o.chat.completions.create(\n",
    "        model=\"gpt4o\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_41_completion(prompt, temperature=0.1):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = llm41.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_deepseek_completion(prompt, temperature=0.1):\n",
    "    messages = [UserMessage(content=prompt)]\n",
    "    response = client_deepseek.complete(\n",
    "        messages=messages,\n",
    "        model=\"DeepSeek-R1\",\n",
    "        temperature=temperature\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    return answer\n",
    "\n",
    "def get_4o_mini_completion(prompt, temperature=0.1):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = llm4o.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_41_mini_completion(prompt, temperature=0.1):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = llm41.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_phi_completion(prompt, temperature=0.1):\n",
    "    messages = [UserMessage(content=prompt)]\n",
    "    response = client_phi.complete(messages=messages, model=\"phi\", temperature=temperature)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_mistral_completion(prompt, temperature=0.1):\n",
    "    messages = [UserMessage(content=prompt)]\n",
    "    response = client_mistral.complete(messages=messages, model=\"mistral-nemo\", temperature=temperature)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_llama_completion(prompt, temperature=0.1):\n",
    "    messages = [UserMessage(content=prompt)]\n",
    "    response = client_llama.complete(messages=messages, model=\"llama-8b\", temperature=temperature)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "dataset = load_dataset(\"boolq\", split=\"train\")\n",
    "\n",
    "def parse_answer(answer_text):\n",
    "    lines = answer_text.strip().splitlines()\n",
    "    for line in reversed(lines):\n",
    "        cleaned = line.strip().strip(string.punctuation).lower()\n",
    "        if cleaned in ['yes', 'no']:\n",
    "            return cleaned == 'yes'\n",
    "    return None\n",
    "\n",
    "def evaluate_model(get_completion_func, model_name, col_name, flagged_indices):\n",
    "    results = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        if i in flagged_indices:\n",
    "            continue\n",
    "        \n",
    "        passage = example[\"passage\"]\n",
    "        question = example[\"question\"]\n",
    "        true_answer = example[\"answer\"]\n",
    "        prompt = f\"Passage: {passage}\\nQuestion: {question}\\nAnswer with yes or no.\"\n",
    "        \n",
    "        try:\n",
    "            answer_text = get_completion_func(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping sample {i} due to error: {e}\")\n",
    "            flagged_indices.add(i)\n",
    "            continue\n",
    "        \n",
    "        pred = parse_answer(answer_text)\n",
    "        is_correct = (pred == true_answer)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"q_number\": i + 1,\n",
    "            \"passage\": passage,\n",
    "            \"question\": question,\n",
    "            \"actual_answer\": true_answer,\n",
    "            col_name: pred\n",
    "        })\n",
    "        \n",
    "        # print(f\"Sample {i+1}:\\n  True Answer: {true_answer}\\n  Model Answer: {pred}\\n  Correct: {is_correct}\\n\")\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    # print(f\"Accuracy for {model_name}: {accuracy:.2f}\\n\")\n",
    "    print(\"Evaluated\")\n",
    "    return accuracy, correct, results\n",
    "\n",
    "#separating flagged questions which violate openai policies and cannot be answered\n",
    "flagged_indices = set()\n",
    "\n",
    "acc_gpt4o, correct_gpt4o, rows_gpt4o = evaluate_model(get_4o_completion, \"OpenAI GPT-4o\", \"4o_pred\", flagged_indices)\n",
    "acc_gpt41, correct_gpt41, rows_gpt41 = evaluate_model(get_41_completion, \"OpenAI GPT-4.1\", \"41_pred\", flagged_indices)\n",
    "acc_deepseekr1, correct_deepseekr1, rows_deepseekr1 = evaluate_model(get_deepseek_completion, \"DeepSeek R1\", \"r1_pred\", flagged_indices)\n",
    "acc_gpt4omini, correct_gpt4omini, rows_gpt4omini = evaluate_model(get_4o_mini_completion, \"OpenAI GPT-4o-mini\", \"4omini_pred\", flagged_indices)\n",
    "acc_gpt41mini, correct_gpt41mini, rows_gpt41mini = evaluate_model(get_41_mini_completion, \"OpenAI GPT-4.1-mini\", \"41_mini_pred\", flagged_indices)\n",
    "acc_phi, correct_phi, rows_phi = evaluate_model(get_phi_completion, \"Phi\", \"phi_pred\", flagged_indices)\n",
    "acc_mistralnemo, correct_mistralnemo, rows_mistralnemo = evaluate_model(get_mistral_completion, \"Mistral NeMo\", \"mistral_pred\", flagged_indices)\n",
    "acc_llama8b, correct_llama8b, rows_llama8b = evaluate_model(get_llama_completion, \"LLaMA 8B\", \"llama_pred\", flagged_indices)\n",
    "\n",
    "df_gpt4o = pd.DataFrame(rows_gpt4o)\n",
    "df_gpt41 = pd.DataFrame(rows_gpt41)\n",
    "df_deepseekr1 = pd.DataFrame(rows_deepseekr1)\n",
    "df_gpt4omini = pd.DataFrame(rows_gpt4omini)\n",
    "df_gpt41mini = pd.DataFrame(rows_gpt41mini)\n",
    "df_phi = pd.DataFrame(rows_phi)\n",
    "df_mistralnemo = pd.DataFrame(rows_mistralnemo)\n",
    "df_llama8b = pd.DataFrame(rows_llama8b)\n",
    "\n",
    "df = df_gpt4o.merge(df_gpt41, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_deepseekr1, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_gpt4omini, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_gpt41mini, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_phi, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_mistralnemo, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "df = df.merge(df_llama8b, on=[\"q_number\", \"passage\", \"question\", \"actual_answer\"])\n",
    "\n",
    "df.to_csv(\"results_combined.csv\", index=False)\n",
    "print(\"Saved results to results.csv\")\n",
    "\n",
    "print(\"Final Accuracies:\")\n",
    "print(f\"OpenAI GPT-4o: {acc_gpt4o:.2f}\")\n",
    "print(f\"GPT-41: {acc_gpt41:.2f}\")\n",
    "print(f\"DeepSeek R1: {acc_deepseekr1:.2f}\")\n",
    "print(f\"GPT-4o-mini: {acc_gpt4omini:.2f}\")\n",
    "print(f\"GPT-41-mini: {acc_gpt41mini:.2f}\")\n",
    "print(f\"Phi: {acc_phi:.2f}\")\n",
    "print(f\"Mistral NeMo: {acc_mistralnemo:.2f}\")\n",
    "print(f\"LLaMA 8B: {acc_llama8b:.2f}\")\n",
    "\n",
    "final_accuracies = {\n",
    "    'final accuracies': {\n",
    "        \"GPT-4o\": {\"accuracy\": acc_gpt4o, \"correct_count\": correct_gpt4o},\n",
    "        \"GPT-41\": {\"accuracy\": acc_gpt41, \"correct_count\": correct_gpt41},\n",
    "        \"DeepSeek R1\": {\"accuracy\": acc_deepseekr1, \"correct_count\": correct_deepseekr1},\n",
    "        \"GPT-4o-mini\": {\"accuracy\": acc_gpt4omini, \"correct_count\": correct_gpt4omini},\n",
    "        \"GPT-41-mini\": {\"accuracy\": acc_gpt41mini, \"correct_count\": correct_gpt41mini},\n",
    "        \"Phi\": {\"accuracy\": acc_phi, \"correct_count\": correct_phi},\n",
    "        \"Mistral NeMo\": {\"accuracy\": acc_mistralnemo, \"correct_count\": correct_mistralnemo},\n",
    "        \"LLaMA 8B\": {\"accuracy\": acc_llama8b, \"correct_count\": correct_llama8b}\n",
    "    },\n",
    "    'flagged_indices' : list(flagged_indices)\n",
    "}\n",
    "\n",
    "with open(\"final_output.json\", \"w\") as f:\n",
    "    json.dump(final_accuracies, f, indent=2)\n",
    "print(\"Saved accuracies to final_accuracies.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17dd7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1414, 6028, 927, 2978, 6306, 7588, 7464, 937, 6442, 8104, 7848, 6701, 2352, 4017, 6713, 1465, 451, 7620, 5708, 4301, 7377, 5203, 8148, 8660, 1879, 3163, 989, 3551, 8032, 6370, 8297, 5616, 4594}\n"
     ]
    }
   ],
   "source": [
    "print(flagged_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
